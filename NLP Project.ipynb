{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "- For POS tagging, should I used filtered list or tokens? (Different results)\n",
    "        #self.pos_tags = self.parts_of_speech_tagging(self.filtered_text)\n",
    "- Do I keep ANP? The text file is pretty bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Manifesto(object):\n",
    "    '''\n",
    "    Creates a Manifesto object.\n",
    "    Can be used to assess different aspects of a text file\n",
    "        including tokens, most common words, parts of speech.\n",
    "    Can be used to create word clouds.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        '''\n",
    "        Initializes the object variables.\n",
    "        '''\n",
    "        self.text = self.reading_file (file_path)\n",
    "        self.tokens = self.tokenize (self.text)\n",
    "        self.filtered_text = self.preprocessing (self.tokens)\n",
    "        self.stemmed_list = self.stemmer(self.filtered_text)\n",
    "        self.pos_tags = self.parts_of_speech_tagging(self.tokens)\n",
    "        self.word_frequency = self.finding_word_frequency(self.filtered_text)\n",
    "        \n",
    "    \n",
    "    def reading_file (self, file_path):\n",
    "        '''\n",
    "        Given a file path, checks if file exists there, reads it, closes it,\n",
    "            and returns the text as a string.\n",
    "\n",
    "        Input:\n",
    "            file_path: string\n",
    "\n",
    "        Return:\n",
    "            text: string\n",
    "        '''\n",
    "        assert os.path.exists(file_path), \"File not found at: \"+str(file_path)\n",
    "        f = open(file_path,'r')    \n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        return text\n",
    "        \n",
    "        \n",
    "    def tokenize (self, text):\n",
    "        '''\n",
    "        Given some text, will return tokens of that text\n",
    "        \n",
    "        Input: \n",
    "            text: string\n",
    "        Output:\n",
    "            token: list of string\n",
    "        '''\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "        \n",
    "    def finding_word_frequency (self, filtered_text):\n",
    "        '''\n",
    "        Given a list, returns the word frequency\n",
    "        \n",
    "        Input:\n",
    "            filtered_text: list of strings\n",
    "        Output:\n",
    "            word frequency: nltk.probability.FreqDist\n",
    "        '''\n",
    "        word_frequency = nltk.FreqDist(filtered_text)\n",
    "        return word_frequency\n",
    "        \n",
    "        \n",
    "    def parts_of_speech_tagging(self, tokens):\n",
    "        '''\n",
    "        Given tokens, assigns parts of speech to each token\n",
    "        \n",
    "        '''\n",
    "        tagged = nltk.pos_tag(tokens)\n",
    "        return tagged      \n",
    "        \n",
    "        \n",
    "    def stemmer (self, filtered_text):\n",
    "        '''\n",
    "        Does stemming/lemmatization of a given text\n",
    "        Input:\n",
    "            filtered_text: list of string\n",
    "            \n",
    "        Output:\n",
    "            a set of stemmed words\n",
    "        '''\n",
    "        st = RSLPStemmer()\n",
    "        stemmed_list = set(st.stem(token) for token in filtered_text)\n",
    "        return stemmed_list\n",
    "        \n",
    "        \n",
    "        \n",
    "    def preprocessing (self, text):\n",
    "        '''\n",
    "        Removes stop words and converts to lower case.\n",
    "        \n",
    "        Input:\n",
    "            text: string\n",
    "            \n",
    "        Output:\n",
    "            filtered_text: list of string\n",
    "        '''\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words=[word.lower() for word in text if word.isalpha()]\n",
    "        filtered_text = [w for w in words if not w in stop_words]\n",
    "        return filtered_text\n",
    "\n",
    "    \n",
    "        \n",
    "    def find_most_frequent_words(self, number):\n",
    "        '''\n",
    "        For a given manifesto object, returns the most common X number of words used\n",
    "            along with the count\n",
    "            \n",
    "        Input:\n",
    "            number: integer\n",
    "            \n",
    "        Output:\n",
    "            mostcommon: list\n",
    "        '''\n",
    "        wordfreqdist = nltk.FreqDist(self.filtered_text)\n",
    "        mostcommon = wordfreqdist.most_common(number)\n",
    "        return mostcommon\n",
    "        \n",
    "        \n",
    "    def create_wordcloud(self, title = None):\n",
    "        '''\n",
    "        Creates a word cloud based on the text of the file.\n",
    "        Removes stop words (which consists of conventional stop words  \n",
    "                and words from my own list)\n",
    "            \n",
    "        Special thanks to the community at stackoverflow\n",
    "        (https://stackoverflow.com/questions/16645799/how-to-create-a-word-cloud-from-a-corpus-in-python)\n",
    "        for this one!\n",
    "        '''\n",
    "        stop_words = list(STOPWORDS)\n",
    "        personal_list = ['pakistan', 'people', 'party', 'manifesto', 'government', 'per', \n",
    "                        'cent', 'will', 'Parliamentarians', 'ANP', 'MQM', 'iii', 'i', 'ii', 'iv', 'v', 'vi', 'PML', 'PTI' ]\n",
    "        stop_words_2 = set(stop_words + personal_list)\n",
    "\n",
    "\n",
    "        wordcloud = WordCloud(\n",
    "            background_color='white',\n",
    "            stopwords=stop_words_2,\n",
    "            max_words=100,\n",
    "            scale=3,\n",
    "            max_font_size=40\n",
    "        ).generate(str(self.text))\n",
    "\n",
    "        fig = plt.figure(1, figsize=(20, 20), dpi = 400)\n",
    "        plt.axis('off')\n",
    "        if title: \n",
    "            fig.suptitle(title, fontsize=30)\n",
    "            fig.subplots_adjust(top=2.3)\n",
    "\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return 'You have stumbled onto a gold mine!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npmln = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/PMLN_2013.txt')\\nmqm = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/MQM_2013.txt')\\npti = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/PTI_2013.txt')\\nanp = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/ANP_2013.txt')\\nji = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/JI_2013.txt')\\n\""
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING MANIFESTO OBJECTS OF THE POLITICAL PARTIES\n",
    "\n",
    "ppp = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/PPP_2013.txt')\n",
    "pmln = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/PMLN_2013.txt')\n",
    "mqm = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/MQM_2013.txt')\n",
    "pti = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/PTI_2013.txt')\n",
    "anp = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/ANP_2013.txt')\n",
    "ji = Manifesto ('/Users/kazi/Desktop/Manifesto Text Files/JI_2013.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
